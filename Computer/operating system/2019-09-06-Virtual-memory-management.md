---
title: 3.2 Virtual memory management
date: 2019-10-15
---

思考如下问题

1. 为什么要引入虚拟内存？
2. 虚拟内存空间的大小由什么因素决定？
3. 虚拟内存是怎么解决问题的？会带来什么问题？

## 1. 虚拟内存的基本概念

### 1.1 传统存储管理方式的特征

具有一次性、驻留性的存储器管理方法称为实存管理，实存管理的缺点是逻辑空间不超过实际内存大小，同时存在的进程数目受限较大。

上节讨论的各种内存管理策略都是为了同时将多个进程保存在内存中，以便允许进行多道程序设计。它们都具有以下两个共同的特征：

1. 一次性。作业必须一次性全部装入内存后，才能开始运行。这会导致两种情况：
   1. 当作业很大而不能全部被装入内存时，将使该作业无法运行。
   2. 当大量作业要求运行时，由于内存不足以容纳所有作业，只能使少数作业先运行，导致多道程序度的下降。
2. 驻留性。作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业运行结束。运行中的进程会因等待 IO 而被阻塞，可能处于长期等待状态。

由以上分析可知，许多在程序运行中不用或暂时不用的程序（数据）占据了大量的内存空间，而一些需要运行的作业又无法装入运行，显然浪费了宝贵的内存资源。

### 1.2 局部性原理

要真正理解虚拟内存技术的思想，首先须了解著名的局部性原理。Bill Joy（SUN 公司 CEO）说过：“在研究所时，我经常开玩笑地说高速缓存是计算机科学中唯一重要的思想。事实上，高速缓存技术确实极大地影响了计算机系统的设计。” 快表、页高速缓存及虚拟内存技术从广义上讲，都属于高速缓存技术。这个技术所依赖的原理就是局部性原理。局部性原理既适用于程序结构，又适用于数据结构（更远地讲，Dijkstra 关于“ `goto` 语句有害” 的著名论文也出于对程序局部性原理的深刻认识和理解）。

局部性原理体现在以下两个方面：

1. 时间局部性。程序中的某条指令一旦执行，不久后该指令可能再次执行；某数据被访问过，不久后该数据可能再次被访问。产生时间局部性的典型原因是程序中存在着大量的循环操作。
2. 空间局部性。一且程序访问了某个存储单元，在不久后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性通过将近来使用的指令和数据保存到高速缓冲存储器中，并使用高速缓存的层次结构实现。空间局部性通常使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上建立了 “内存-外存” 的两级存储器结构，利用局部性原理实现高速缓存。

### 1.3 虚拟存储器的定义和特征

将大容量的外存作为内存的直接延伸，对内存、外存（交换区）实施统一管理，虚拟存储器具有多次性和对换性。仅把进程的一部分调入内存即可运行。

基于局部性原理，在程序装入时，将程序的一部分装入内存，而将其余部分留在外存，就可启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。

之所以将其称为虚拟存储器，是因为这种存储器实际上并不存在，只是由于系统提供了部分装入、请求调入和置换功能后（对用户完全透明），给用户的感觉是好像存在一个比实际物理内存大得多的存储器。虚拟存储器的大小由计算机的地址结构决定，并不是内存和外存的简单相加。虚拟存储器有以下三个主要特征：

1. 多次性。多次性是指无须在作业运行时一次性地全部装入内存，而允许被分成多次调入内存运行。
2. 对换性。对换性是指无须在作业运行时一直常驻内存，而允许在作业的运行过程中，进行换进和换出。
3. 虚拟性。虚拟性是指从逻辑上扩充内存的容量，使用户所看到的内存容量远大于实际的内存容量。

### 1.4 虚拟内存技术的实现

虚拟内存技术允许将一个作业分多次调入内存。采用连续分配方式时，会使相当一部分内存空间都处于暂时或 “永久” 的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。

虚拟内存的实现有以下三种方式：

- 请求分页存储管理。
- 请求分段存储管理。
- 请求段页式存储管理。

管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面：

- 一定容量的内存和外存。
- 页表机制（或段表机制），作为主要的数据结构。
- 中断机构，当用户程序要访问的部分尚未调入内存时，则产生中断。
- 地址变换机构，逻辑地址到物理地址的变换。

## 2. 请求分页管理方式

请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。

在请求分页系统中，只要求将当前需要的一部分页面装入内存，便可以启动作业运行。在作业执行过程中，当所要访问的页面不在内存中时，再通过调页功能将其调入，同时还可通过置换功能将暂时不用的页面换出到外存上，以便腾出内存空间。

为了实现请求分页，系统必须提供一定的硬件支持。除了需要一定容量的内存及外存的计算机系统，还需要有页表机制、缺页中断机构和地址变换机构。

### 2.1 页表机制

请求分页系统的页表机制不同于基本分页系统，请求分页系统在一个作业运行之前不要求全部一次性调入内存，因此在作业的运行过程中，必然会出现要访问的页面不在内存中的情况，如何发现和处理这种情况是请求分页系统必须解决的两个基本问题。为此，在请求页表项中增加了 4 个字段，如下：

```c
页号 | 物理块号 | 状态位P | 访问字段A | 修改位 M | 外存地址
```

增加的 4 个字段说明如下：

- 状态位 P。用于指示该页是否已调入内存，供程序访问时参考。
- 访问字段 A。用于记录本页在一段时间内被访问的次数，或记录本页最近已有多长时间未被访问，供置换算法换出页面时参考。
- 修改位 M。标识该页在调入内存后是否被修改过。
- 外存地址。用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考。

（我的理解：在外存时记录外存的地址，在内存时记录内存的地址）

### 2.2 缺页中断机构

在请求分页系统中，每当所要访问的页面不在内存中时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。此时应将缺页的进程阻塞（调页完成唤醒），若内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中的相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存）。

缺页中断作为中断，同样要经历诸如保护 CPU 环境、分析中断原因、转入缺页中断处理程序、恢复CPU环境等几个步骤。但与一般的中断相比，它有以下两个明显的区别：

- 在指令执行期间而非一条指令执行完后产生和处理中断信号，属于内部中断。
- 一条指令在执行期间,可能产生多次缺页中断。

### 2.3 地址变换机构

请求分页系统中的地址变换机构，是在分页系统地址变换机构的基础上，为实现虚拟内存，又增加了某些功能而形成的。

在进行地址变换时，先检索快表（P184）：

- 若找到要访问的页，则修改页表项中的访问位（写指令还需要重置修改位），然后利用页表项中给出的物理块号和页内地址形成物理地址。
- 若未找到该页的页表项，则应到内存中去査找页表，再对比页表项中的状态位 P，看该页是否已调入内存，未调入则产生缺页中断，请求从外存把该页调入内存。

## 3. 页面置换算法

进程运行时，若其访问的页面不在内存中而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。

选择调出页面的算法就称为页面置換算法。好的页面置换算法应有较低的页面更换频率，也就是说，应将以后不会再访问或以后较长时间内不会再访问的页面先调出。

常见的置换算法有以下 4 种。

### 3.1 最佳（OPT）页面置换算法

最佳（Optimal，OPT）置换算法选择的被淘汰页面是以后永不使用的页面，或是在最长时间不再被访问的页面，以便保证获得最低的缺页率。然而，由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。

最佳置换算法可用来评价其他算法。假定系统为某进程分配了三个物理块，并考虑有页面号引用串 7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1。进程运行时，先将 7，0，1 三个页面依次装入内存。进程要访问页面 2 时，产生缺页中断，根据最佳置换算法，选择将第 18 次访问才需调入的页面 7 淘汰。然后，访问页面 0 时，因为它已在内存中，所以不必产生缺页中断。访问页面 3 时，又会根据最佳置换算法将页面 1 淘汰……以此类推，如下表，可以看出采用最佳置换算法时的情况。

| 访问页面 | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 2    | 1    | 2    | 0    | 1    | 7    | 0    | 1    |
| -------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 物理块1  | 7    | 7    | 7    | 2    |      | 2    |      | 2    |      |      | 2    |      |      | 2    |      |      |      | 7    |      |      |
| 物理块2  |      | 0    | 0    | 0    |      | 0    |      | 4    |      |      | 0    |      |      | 0    |      |      |      | 0    |      |      |
| 物理块3  |      |      | 1    | 1    |      | 3    |      | 3    |      |      | 3    |      |      | 1    |      |      |      | 1    |      |      |
| 缺页否   | √    | √    | √    | √    |      | √    |      | √    |      |      | √    |      |      | √    |      |      |      | √    |      |      |

最长时间不被访问和以后被访问次数最小是不同的概念，在理解 OPT 算法时千万不要混淆。

可以看到，发生缺页中断的次数为 9，页面置换的次数为 6。

### 3.2 先进先出（FIFO）页面置换算法

优先淘汰最早进入内存的页面，即在内存中驻留时间最久的页面。该算法实现简单，只需把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面。但该算法与进程实际运行时的规律不适应，因为在进程中，有的页面经常被访问。

这里仍用上面的实例采用 FIFO 算法进行页面置换。进程访问页面 2 时，把最早进入内存的页面 7 换出。然后访问页面 3 时，把 2，0，1 中最先进入内存的页面 0 换出。由下表可以看出，利用 FIFO 算法时进行了 12 次页面置换，比最佳置换算法正好多一倍。

| 访问页面 | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 2    | 1    | 2    | 0    | 1    | 7    | 0    | 1    |
| -------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 物理块1  | 7    | 7    | 7    | 2    |      | 2    | 2    | 4    | 4    | 4    | 0    |      |      | 0    | 0    |      |      | 7    | 7    | 7    |
| 物理块2  |      | 0    | 0    | 0    |      | 3    | 3    | 3    | 2    | 2    | 2    |      |      | 1    |      |      |      | 1    | 1    | 0    |
| 物理块3  |      |      | 1    | 1    |      | 1    | 0    | 0    | 0    | 3    | 3    |      |      | 3    | 2    |      |      | 2    | 2    | 1    |
| 缺页否   | √    | √    | √    | √    |      | √    | √    | √    | √    | √    | √    |      |      | √    | √    |      |      | √    | √    | √    |

FIFO 算法还会产生所分配的物理块数增大而页故障数不减反增的异常现象，这由 Belady 于 1969 年发现，故称为  Belady 异常。只有 FIFO 算法可能出现 Belady 异常，LRU 和 OPT 算法永远不会出现 Belady 异常。

如下表所示，页面访问顺序为 3，2，1，0，3，2，4，3，2，1，0，4。若采用 FIFO 置换算法，当分配的物理块为 3 个时，缺页次数为 9 次；当分配的物理块为 4 个时，缺页次数为 10 次。分配给进程的物理块增多，但缺页次数不增反减。

| 访问页面   | 3    | 2    | 1    | 0    | 3    | 2    | 4    | 3    | 2    | 1    | 0    | 4    |
| ---------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 物理块1    | 3    | 3    | 3    | 0    | 0    | 0    | 4    |      |      | 4    | 4    |      |
| 物理块2    |      | 2    | 2    | 2    | 3    | 3    | 3    |      |      | 1    | 1    |      |
| 物理块3    |      |      | 1    | 1    | 1    | 2    | 2    |      |      | 2    | 0    |      |
| 缺页否     | √    | √    | √    | √    | √    | √    | √    |      |      | √    | √    |      |
| `物理块1*` | 3    | 3    | 3    | 3    |      |      | 4    | 4    | 4    | 4    | 0    | 0    |
| `物理块2*` |      | 2    | 2    | 2    |      |      | 2    | 3    | 3    | 3    | 3    | 4    |
| `物理块3*` |      |      | 1    | 1    |      |      | 1    | 1    | 2    | 2    | 2    | 2    |
| `物理块4*` |      |      |      | 0    |      |      | 0    | 0    | 0    | 1    | 1    | 1    |
| 缺页否     | √    | √    | √    | √    |      |      | √    | √    | √    | √    | √    | √    |

### 3.3 最近最久未使用（LRU）页面置换算法

选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。

再对上面的实例采用 LRU 算法进行页面置换，如下表所示。进程第一次对页面 2 访问时，将最近最久未被访问的页面 7 置换出去。然后在访问页面 3 时，将最近最久未使用的页面 1 换出。

| 访问页面 | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 2    | 1    | 2    | 0    | 1    | 7    | 0    | 1    |
| -------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 物理块1  | 7    | 7    | 7    | 2    |      | 2    |      | 4    | 4    | 4    | 0    |      |      | 1    |      | 1    |      | 1    |      |      |
| 物理块2  |      | 0    | 0    | 0    |      | 0    |      | 0    | 0    | 3    | 3    |      |      | 3    |      | 0    |      | 0    |      |      |
| 物理块3  |      |      | 1    | 1    |      | 3    |      | 3    | 2    | 2    | 2    |      |      | 2    |      | 2    |      | 7    |      |      |
| 缺页否   | √    | √    | √    | √    |      | √    |      | √    | √    | √    | √    |      |      | √    |      | √    |      | √    |      |      |

前 5 次置换的情况与最佳置换算法相同，但两种算法并无必然联系。实际上，LRU 算法根据各页以前的情况，是 “向前看” 的，而最佳置换算法则根据各页以后的使用情况，是 “向后看” 的。

LRU 算法的性能较好，但需要寄存器和栈的硬件支持。LRU 是堆栈类的算法。理论上可以证明，堆栈类算法不可能出现 Belady 异常。FIFO 算法基于队列实现，不是堆栈类算法。

### 3.4 时钟（clock）置换算法

LRU 算法的性能接近于 OPT 算法，但实现起来比较困难，且开销大；FIFO 算法实现简单，但性能差。因此，操作系统的设计者尝试了很多算法，试图用比较小的开销接近于 LRU 算法的性能，这类算法都是 CLOCK 算法的变体。因为算法要循环扫描缓冲区，像时钟的指针一样转动，所以称为 CLOCK 算法。

简单的 CLOCK 算法给每帧关联一个附加位，称为使用位。当某页首次装入主存时，将该帧的使用位设置为 1；当该页随后再被访问到时，其使用位也被置为1。对于页替换算法，用于替换的候选帧集合可视为一个循环缓沖区，并有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧，当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为 0 的一帧。每当遇到一个使用位为 1 的帧时，操作系统就将该位重新置为0；若在这个过程开始时，缓冲区中所有帧的使用位均为 0；则选择遇到的第一个帧替换；若所有顿的使用位均为1，则指针在缓区中完整地循环一周，把所有使用位都置为 0，并停留在最初的位置上，替换该帧中的页。由于该算法循环检查各页面的情况，故称 CLOCK 算法，又称最近未用（Not Recently Used，NRU）算法。

CLOCK 算法的性能比较接近 LRU 算法，而通过增加使用的位数目，可以使得 CLOCK 算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型 CLOCK 置换算法。这样，每帧都处于以下 4 种情况之一：

1. 最近未被访问，也未被修改（u=0，m=0）。
2. 最近被访问，但未被修改（u=1，m=0）。
3. 最近未被访问，但被修改（u=0，m=1）。
4. 最近被访问，被修改（u=1，m=1）。

算法执行如下操作步骤：

1. 从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧（u=0，m=0）用于替换。
2. 若第 1步失败，则重新扫描，查找（u=0，m=1）的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成 0。
3. 若第 2 步失败，则指针将回到它的最初位置，且集合中所有的使用位均为 0。重复第 1 步，并且若有必要，重复第 2 步，以便可以找到供替换的帧。

改进型 CLOCK 算法优于简单 CLOCK 算法的地方在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，因而这样做会节省时间。

有些读者会认为 CLOCK 算法和改进型 CLOCK 算法记忆起来不易。为方便记忆，我们将其总结如下。

操作系统中任何经过优化而有效的页面置换算法都有一个原则，即尽可能保留曾经使用过的页面，而淘汰未使用的页面，认为这样可以在总体上减少换页次数。CLOCK 算法只考虑到是否访问过，因此被访问过的当然尽可能留下，未使用过的就淘汰；而改进型 CLOCK 算法对使用过的页而又做了细分，分为使用过但未修改过和使用过且修改过。因此，若有未使用过的页面，则当然首先把它换出，若全部页面都使用过，则当然优先把未修改过的页面换出（P188）。

## 4. 页面分配策略

### 4.1 驻留集大小

对于分页式的虚拟内存，在进程准备执行时，不需要也不可能把一个进程的所有页都读入主存。因此，操作系统必须决定读取多少页，即決定给特定的进程分配几个页框。给一个进程分配的物理页框的集合就是这个进程的驻集。需要考虑以下几点：

1. 分配给一个进程的存储量越小，任何时候驻留在主存中的进程数就越多，从而可以提高处理机的时间利用效率。
2. 若一个进程在主存中的页数过少，则尽管有局部性原理，页错误率仍然会相对较高。
3. 若页数过多，则由于局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有明显的影响。

基于这些因素，现代操作系统通常采用三种策略。

1. 固定分配局部置換。它为每个进程分配一定数目的物理块，在整个运行期间都不改变。若进程在运行中发生缺页。则只能从该进程在内存中的页面中选出一页换出，然后调入需要的页面。实现这种策略时，难以确定应为每个进程分配的物理块数目：太少会频繁出现缺页中断，太多又会使 CPU 和其他资源利用率下降。
2. 可变分配全局置换。这是最易于实现的物理块分配和置换策略，它为系统中的每个进程分配一定数目的物理块，操作系统自身也保持一个空闲物理块队列。当某进程发生缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，并将欲调入的页装入其中。这种方法比固定分配局部置换更加灵活，可以动态增加进程的物理块，但也存在弊端，如它会盲目地给进程增加物理块，从而导致系统多道程序的并发能力下降。
3. 可变分配局部置换。它为每个进程分配一定数目的物理块，当某个进程发生缺页时，只允许从该进程在内存的页面中选出一页换出，因此不会影响其他进程的运行。若进程在运行中繁地缺页，则系统再为该进程分配若干物理块，直至该进程缺页率趋于适当程度；反之，若进程运行中的缺页率特别低，则可适当减少分配给该进程的物理块。比起可变分配全局置换，这种方法不仅可以动态增加进程物理块的数量，还能动态减少进程物理块的数量，在保证进程不会过多地调页的同时，也保持了系统的多道程序并发能力。当然它需要更复杂的实现，也需要更大的开销，但对比频繁地换入换出所浪费的计算机资源，这种牺牲是值得的。

### 4.2 调入页面的时机

为确定系统将进程运行时所缺的页面调入内存的时机，可采取以下两种调页策略：

1. 预调页策略。根据局部性原理，一次调入若干相邻的页可能会比一次调入一页更高效。但若调入的一批页面中大多数都末被访问，则又是低效的。因此，需要采用以预测为基础的预调页策路，将预计在不久之后便会被访问的页面预先调入内存。但目前预调页的成功率仅约 50%。故这种策略主要用于进程的首次调入，由程序员指出应先调入哪些页。
2. 请求调页策略。进程在运行中需要访问的页面不在内存而提出请求，由系统将所需页面调入内存。由这种策略调入的页一定会被访问，且这种策略比较易于实现，故在目前的虚拟存储器中大多采用此策略。它的缺点是毎次只调入一页，调入/调出页面数多时会花费过多的 IO 开销。

预调入实际上就是运行前的调入，请求调页实际上就是运行期间调入。一般情况下，两种调页策略会同时使用。

### 4.3 从何处调入页面

请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页面的对换区。对换区通常采用连续分配方式，而文件区采用离散分配方式，故对换区的磁盘 IO 速度比文件区的更快。这样，从何处调入页面就存在三种情况：

1. 系统拥有足够的对换区空间。可以全部从对换区调入所需页面，以提高调页速度。为此，在进程运行前，需将与该进程有关的文件从文件区复制到对换区。
2. 系统缺少足够的对换区空间。凡不会被修改的文件都直接从文件区调入；而当换出这些页面时，由于它们未被修改而不必再将它们换出。但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入（因为读的速度比写的速度快）。
3. UNIX 方式。与进程有关的文件都放在文件区，故末运行过的页面都应从文件区调入。曾经运行过但又被换出的页面，由于放在对换区，因此下次调入时应从对换区调入。进程请求的共享页面若被其他进程调入内存，则无须再从对换区调入。

## 5. 抖动

在页面置换过程中，一种最槽糕的情形是，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上又要换出主存，这种频繁的页面调度行为称为抖动或颠簸。若一个进程在换页上用的时间多于执行时间，则这个进程就在颠簸。

频繁发生缺页中断（抖动）的主要原因是，某个进程频繁访问的页面数目高于可用的物理页帧数目。虚拟内存技术可在内存中保留更多的进程以提高系统效率。在稳定状态，几乎主存的所有空间都被进程块占据，处理机和操作系统可以直接访问到尽可能多的进程。然而，如果管理不当，那么处理机的大部分时间都将用于交换块，即请求调入页面的操作，而不是执行进程的指令，因此会大大降低系统效率。

## 6. 工作集

工作集是指在某段时间间隔内，进程要访问的页面集合。基于局部性原理，可以用最近访问过的页面来确定工作集。一般来说，工作集 W 可由时间 t 和工作集窗口大小 Δ 来确定。例如，某进程对页面的访问次序如下：

```c
1,4,2,3,5,3,2,2,1,1,1,3,4,5,4,4,2,1,1,3,3
             |t1                       |t2
```

假设系统为该进程设定的工作集窗口大小 Δ 为 5，则在 t1 时刻，进程的工作集为`{2,3,5}` ，在 t2 时刻,进程的工作集为 `{1,2,3,4}`。

实际应用中，工作集窗口会设置得很大，即对于局部性好的程序，工作集大小一般会比工作集窗口 Δ 小很多。工作集反映了进程在接下来的一段时间内很有可能会频繁访问的页面集合，因此，若分配给进程的物理块小于工作集大小，则该进程就很有可能频繁缺页，所以为了防止这种抖动现象，一般来说分配给进程的物理块数（即驻留集大小）要大于工作集大小。

工作集模型的原理是，让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块。落在工作集内的页面需要调入驻留集中，而落在工作集外的页面可从驻留集中换出。若还有空闲物理块，则可以再调一个进程到内存以增加多道程序数。若所有进程的工作集之和超过了可用物理块的总数，则操作系统会暂停一个进程，将其页面调出并将其物理块分配给其他进程，防止出现抖动现象。

## 7. 地址翻译

本小节引入一个实例来说明虚实地址的变换过程，考虑到统考试题近来出现了学科综合的趋势，这里结合计算机组成原理中的 Cache 部分进行讲解。对于不参加统考的读者，可以看到翻译出实地址为止，对于参加统考却还没有复习计算机组成原理的读者，可在复习完计算机组成原理后，再回来看本章的内容。

设某系统满足以下条件：

- 有一个 TLB 与ー个 data Cache。
- 存储器以字节为编址单位。
- 虚拟地址 14 位。
- 物理地址 12 位。
- 页面大小为 64 B。
- TLB 为四路组相联，共有 16 个条目。
- data Cache 是物理寻址、直接映射的，行大小为 4B，共有 16 组。

写出访问地址为 0x03d4、0x00f1 和 0x0229 的过程。

因为本系统以字节编址，页面大小为 64B，则页内偏移地位为 log₂(64B/1B)=6 位，所以虚拟页号为14-6=8 位，物理页号为 12-6=6 位。因为 TLB 为四路组相联，共有 16 个条目，则 TLB 共有16/4=4 组，故虚拟页号中低 log₂4=2 位就为组索引，高6位就为 TLB 标记。又因为 Cache 行大小为 4B，因此物理地址中低 log₂4=2 位为块偏移， Cache 共有 16 组,可知接下来 log₂16=4 位为组索引，剩下高 6 位作为标记（P191）。

TLB 信息如下：

| 位   | 标记 | 物理页号 | 有效位 | 标记 | 物理页号 | 有效位 | 标记 | 物理页号 | 有效位 | 标记 | 物理页号 | 有效位 |
| ---- | ---- | -------- | ------ | ---- | -------- | ------ | ---- | -------- | ------ | ---- | -------- | ------ |
| 0    | 03   | -        | 0      | 09   | 0D       | 1      | 00   | -        | 0      | 07   | 02       | 1      |
| 1    | 03   | 2D       | 1      | 02   | -        | 0      | 04   | -        | 0      | 0A   | -        | 0      |
| 2    | 02   | -        | 0      | 08   | -        | 0      | 06   | -        | 0      | 03   | -        | 0      |
| 3    | 07   | -        | 0      | 03   | 0D       | 1      | 0A   | 34       | 1      | 02   | -        | 0      |

部分页表信息如下：

| 虚拟页号 | 物理页号 | 有效位 | 虚拟页号 | 物理页号 | 有效位 |
| -------- | -------- | ------ | -------- | -------- | ------ |
| 00       | 28       | 1      | 08       | -        | 0      |
| 01       | -        | 0      | 09       | 17       | 1      |
| 02       | 33       | 1      | 0A       | 09       | 1      |
| 03       | 02       | 1      | 0B       | -        | 0      |
| 04       | -        | 0      | 0C       | -        | 0      |
| 05       | 16       | 1      | 0D       | 2D       | 1      |
| 06       | -        | 0      | 0E       | 11       | 1      |
| 07       | -        | 0      | 0F       | 0D       | 1      |

data Cache内容如下：

| 索引 | 标记位 | 有效位 | 块0  | 块1  | 块2  | 块3  |
| ---- | ------ | ------ | ---- | ---- | ---- | ---- |
| 0    | 19     | 1      | 99   | 11   | 23   | 11   |
| 1    | 15     | 0      | -    | -    | -    | -    |
| 2    | 1B     | 1      | 00   | 02   | 04   | 08   |
| 3    | 36     | 0      | -    | -    | -    | -    |
| 4    | 32     | 1      | 43   | 6D   | 8F   | 09   |
| 5    | 0D     | 1      | 36   | 72   | F0   | 1D   |
| 6    | 31     | 0      | -    | -    | -    | -    |
| 7    | 16     | 1      | 11   | C2   | DF   | 03   |
| 8    | 24     | 1      | 3A   | 00   | 51   | 89   |
| 9    | 2D     | 0      | -    | -    | -    | -    |
| A    | 2D     | 1      | 93   | 15   | DA   | 3B   |
| B    | 0B     | 0      | -    | -    | -    | -    |
| C    | 02     | 0      | -    | -    | -    | -    |
| D    | 16     | 1      | 04   | 96   | 34   | 15   |
| E    | 13     | 1      | 83   | 77   | 1B   | D3   |
| F    | 14     | 0      | -    | -    | -    | -    |

先把十六进制的虚拟地址转化为二进制形式，虚拟地址结构如下

```c
0x03d4 : 00001111 010100
0x00f1 : 00000011 110001
0x0229 : 00001000 101001
```

得到每个地址的组索引和 TLB 标记，接下来就要找出每个地址的页面在不在主存中，若在主存中，则还要找出物理地址。

对于 0x03d4，组索引为 3，TLB 标记为 0x03，査 TLB，第 3 组中正好有标记为 03 的项，有效位为 1，可知页面在主存中，对应的物理地址为 0d(001101)，再拼接页内地址 010100，可得物理地址为 0x354(001101010100)。

对于 0x00f1，组索引为 3，TLB 标记为 0x00，査 TLB，第 3 组中没有标记为 00 的项，再去找页表，虚拟页号为 0x03，页表第 3 行的有效位为 1，可知页面在主存中，物理地址为 02(000010)，再拼接页内地址 110001，可得物理地址为 0x0b1(000010110001)。

对于 0x0229，组索引为 0，TLB 标记为 0x02，查 TLB，第 0 组中没有标记为 02 的项，再去找页表，虚拟页号为0x08，页表第 8 行的有效位为 0，页面不在主存中，产生缺页中断。

找出在主存中的页面的物理地址后，就要通过物理地址访问数据，接下来要找该物理地址的内容在不在 Cache 中。物理地址结构如下

```c
0x354 : 001101 010100
0x0b1 : 000010 110001
```

对于 0x354， Cache 索引为 5，Cache 标记为 0x0d，对照 Cache 中索引为 5 的行，标记正好为 0d，有效位为 1，可知该块在 Cache 中，偏移 0，即块 0，可得虚拟地址 0x03d4 的内容为 36H。

对于 0x0b1，Cache 索引为 c，Cache 标记为 0x02，对照 Cache 中索引为 c 的行，有效位为 0，可知该块不在 Cache 中，要去主存中査找物理页号为 2、偏移为 0x31 的内容。

以上例子基本覆盖了从虚拟地址到 Cache 查找内容的所有可能出现的情况，读者务必要掌握此节的内容，査找顺序是从 TLB 到页表（TLB 不命中），再到 Cache 和主存，最后到外存。

## 8. 小结

本节开头提出的问题的参考答案如下：

1. 为什么要引入虚拟内存？

   上一节提到过，多道程序并发执行不仅使进程之间共享了处理器，而且同时共享了主存。然而，随着对处理器需求的增长，进程的执行速度会以某种合理平滑的方式慢下来。但是，若同时运行的进程太多，则需要很多的内存，当一个程序没有内存空间可用时，那么它甚至无法运行。所以，在物理上扩展内存相对有限的条件下，应尝试以一些其他可行的方式在逻辑上扩充内存。

2. 虚拟内存空间的大小由什么因素决定？

   虚存的大小要同时满足两个条件：

   1. 虚存的大小 ≤ 内存容量和外存容量之和，这是硬件的硬性条件规定的，若虚存大小超过了这个容量，则没有相应的空间来供虚存使用。
   2. 虚存的大小 ≤ 计算机的地址位数能容纳的最大容量。假设地址是 32 位的，按字节编址，一个地址代表 1B 存储空间，则虚存的大小≤4GB（2³²B）。这是因为若虚存的大小超过 4GB，则 32 位的地址将无法访问全部虚存，也就是说 4GB 以后的空间被浪费了，相当于没有一样，没有任何意义。

   实际虚存的容量是取条件 1和 2 的交集，即两个条件都要满足，光满足一个条件是不行的。

3. 虚拟内存是怎么解决问题的？会带来什么问题？

   虚拟内存使用外存上的空间来扩充内存空间，通过一定的换入换出，使得整个系统在逻辑上能够使用一个远远超出其物理内存大小的内存容量。因为虚拟内存技术调换页面时需要访问外存，会导致平均访存时间下降，若使用了不合适的替换算法，则会大大降低系统性能。

本节学习了 4 种页面置换算法，要把它们与处理机调度算法区分开。当然，这些调度算法之间也是有联系的，它们都有一个共同点，即通过一定的准则决定资源的分配对象。在处理机调度算法中这些准则比较多，有优先级、响应比、时间片等，而在页面调度算法中就比较简单，即是否被用到过或近段时间内是否经常使用。在操作系统中，几乎每类资源都会有相关的调度算法，读者通过将这些调度算法作为线索，可把整个操作系统的课程连成一个整体。