---
title: 3.1 The Concept of Memory Management
date: 2019-10-15
---

思考如下问题

1. 为什么要进行内存管理？
2. 叶式管理中每个页表项大小的下限如何决定？
3. 多级页表解决了什么问题？又会带来什么问题？

存储器是计算机的重要组成部分，分为外存和内存。外存就是我们常见的磁盘，用来存储数据，即使断电也不会丢失。内存是 CPU 读写数据的地方，CPU 要想使用外存的数据，必须先将外存数据读取到内存后再使用。

操作系统中提及的存储器管理，其主要对象就是内存管理，而文件系统才会涉及到比较多的外存知识。

内存三要素：速度快，容量大、便宜。显然便宜限制了前面两个因素，因此提出了多层结构的存储器结构。一般分为三类：寄存器、主存、辅存。现在的计算机又细分了一些，如下

| 名字           | 类型       |
| -------------- | ---------- |
| 寄存器         | CPU 寄存器 |
| 高速缓存       | 主存       |
| 主存储器       | 主存       |
| 磁盘缓存       | 主存       |
| 固定磁盘       | 辅存       |
| 可移动存储介质 | 辅存       |

越前面的速度越快，容量越小，价格越高。

1. 可执行存储器

   寄存器和主存被称为可执行存储器，存放于其中的信息，CPU 可以通过一条指令（load 或者 store）就可以读取，而辅存需要通过 I/O 设备实现，这里就涉及了 I/O 中断，速度自然很慢（相差 3 个数量级）。我们存储管理主要讲可执行存储器管理，辅存知识归为设备和文件管理。

2. 主存储器和寄存器

   主存储器简称内存，用来保存进程运行时的程序和数据。一开始 CPU 是直接读取内存的数据或者指令运行的，后来 CPU 的执行速度远大于内存的读写速度，因此在中间加入了寄存器和高速缓存。常用的数据或指令放到寄存器和高速缓存中，CPU 从寄存器中读取数据，如果没有想要的数据，再从下一层存储器中读取。

   寄存器具有和处理器相同的速度，但很贵，因此容量有限，主要用来存放处理机运行时的数据（运行指针、返回地址等等）。

3. 高速缓存和磁盘缓存

   高速缓存在第二层，因此访问速度比主存快，主要用来备份主存中比较常用的数据。以减少处理机对主存的访问次数，提高执行速度。层次结构的形成和程序执行的局部性原理有关，也就是 CPU 接下来执行的指令和需要的数据往往和当前指令或者数据相近。高速缓存可能分为好几层，但是原理都一样，因此这里合并为一层讲解。

   磁盘缓存其实属于主存的一部分（而不是独立的一部分），主要存放一些常用的磁盘数据和信息。减少访问磁盘的次数。这里要区分于高速缓存，高速缓存是实际存在的。文件通常存储在磁盘中，要使用的时候会调入主存或者磁盘缓存。

## 1. 内存管理的基本原理和要求

内存管理（Memory Management）是操作系统设计中最重要和最复杂的内容之一。虽然计算机硬件一直在发展，内存容量也在不断增长，但仍然不可能将所有用户进程和系统所需要的全部程序与数据放入主存，因此操作系统必须对内存空间进行合理的划分和有效的动态分配。操作系统对内存的划分和动态分配，就是内存管理的概念。

有效的内存管理在多道程序设计中非常重要，它不仅可以方便用户使用存储器、提高内存利用率，还可以通过虚拟技术从逻辑上扩充存储器。

内存管理的功能有：

- 内存空间的分配与回收。由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。
- 地址转换。在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。
- 内存空间的扩充。利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。
- 存储保护。保证各道作业在各自的存储空间内运行，互不干扰。

在进行具体的内存管理之前，需要了解进程运行的基本原理和要求。

### 1.1 程序装入和链接

用户程序要在系统中运行，必须先调入主存，然后再将其转变为一个可以执行的程序，一般经过以下步骤（P148）：

1. 编译（Compiler）：由编译程序将用户源代码编译成若干目标模块
2. 链接（Linker）：将编译后的若干目标模块和它们所需的库函数链接一起形成装入模块（Load Module）。使用 `readelf` 指令可以查看。
3. 装入：由装入程序（Loader）将装入模块装入内存。

我们主要将程序（含数据）的链接和装入过程。编译交给编译器，例如 C 的编译器 `gcc` 。

---

源程序经过编译后，可得到一组目标模块。链接程序的功能就是将这组目标模块以及它们所需要的库函数装配成一个完整的装入模块。在对目标模块进行链接时，根据进行链接的时间不同，可把链接分成如下三种。

1. 静态链接方式（Static Linking）

   在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的装配模块，以后不再拆开。我们把这种事先进行链接的方式称为静态链接方式。例如下面三个目标模块

   | 目标模块  | 调用模块         | 起始地址变化  |
   | --------- | ---------------- | ------------- |
   | A(0～L-1) | {CALL B; return} | 不变          |
   | B(0~M-1)  | {CALL C; return} | (L~L+M-1)     |
   | C(0~N-1)  | { return; }      | (L+M~L+M+N-1) |

   A、B 和 C 三个目标模块进行链接的时候，如果以 A 为基址进行链接，那么 B、C 的起始地址都会相应的改变，对应的外部调用符号都要变换为相对地址，然后将合成的一整个装入模块装入内存。

2. 装入时动态链接（Load-time Dynamic Linking）

   - 用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的链接方式。
   - 若发生一个外部模块调用事件，将引起装入程序去找相应的外部目标模块，并将它装入内存。同时按照静态链接的方式修改目标模块中的相对地址。

   优点：1）便于修改和更新。由于目标模块分开存放，所以要修改和更新各目标模块是件非常容易的事。

   2）便于实现目标模块的共享。采用静态链接方式时，每个应用模块都必须含有其目标模块的拷贝，无法实现对目标模块的共享。如果采用装入时动态链接方式，OS 就很容易将一个目标模块链接到几个应用模块上，实现多个应用程序对该模块的共享

3. 运行时动态链接（Run-time Dynamic Linking）

   在多数情况下，应用程序在运行时，每次要运行的模块可能是不相同的。典型例子就是错误处理用的目标模块，如果程序整个运行过程正常，就不会用到该模块

   这是对装入时动态链接的一种改进，将目标模块的装入推迟到程序执行时才进行，因此凡是执行过程没使用的目标模块都不会被装入内存。

   优点是不仅加快装入速度，还节省内存空间。

---

为了易于阐述，这里介绍无需链接的单个目标模块的装入过程。将该装入模块装入内存有三种方式

1. 绝对装入方式（Absolute Loading Mode）。在编译时，若知道程序将驻留在内存的某个位置，则编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将持续和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需要对程序和数据的地址进行修改。
   
   绝对装入方式只适用于单道程序环境。另外，程序中使用的绝对地址，可在编译或汇编时给出，也可程序员直接赋予。而通常情况下在程序中采用的是符号地址，编译或汇编时再转换为绝对地址。
   
   - 环境：只适用于单道程序环境。
   - 事先知道程序驻留在内存的什么位置。
   - 绝对装入程序（Loader）按照装入模块中的地址，将程序和数据装入内存。
   - 程序中的逻辑地址与实际内存地址完全相同，不须对程序和数据的地址进行修改。
   - 特点：内存大小限制，能装入内存并执行的进程数大大减少。
   
2. 可重定位装入方式（Relocation Loading Mode）。在多道程序环境下，多个目标模块的起始地址（简称始址）通常都从 0 开始，程序中的其他地址都是相对于始址的，此时应采用可重定位装入方式。根据内存的当前情况，将装入模块装入内存的适当位置。装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成的，所以又称为静态重定位（P149）.

   静态重定位的特点是，一个作业装入内存时，必须给他分配要求的全部内存空间，若没有足够的内存，则不能装入该作业。此外，作业一旦进入内存，整个运行期间就不能在内存中移动，也不能再申请内存空间。

   - 环境：多道程序环境
   - 装入模块的起始地址通常都是从 0 开始的，程序中的其他地址也都是相对于起始地址计算的。
   - 根据内存的当前情况，将装入模块装入到内存的适合位置。
   - 地址变换通常是在装入时一次完成的，以后都不再改变，所以是静态重定位。
   - 特点：无需硬件支持；程序不能在内存中移动；要求程序的存储空间是连续的，不能把程序放在若干个不连续的区域中。

3. 动态运行时的装入方式（Dynamic Run-time Loading）。程序在内存中若发生移动，则需要采用动态的装入方式。装入程序把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。这种方式需要一个重定位寄存器的支持（P149）。

   丛台重定位的特点如下：可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。

   - 环境：多道程序环境
   - 程序在运行过程中在内存中的位置可能改变（对换功能中进程的换进换出），装入程序把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行
   - 特点：程序在内存中可以浮动，不要求整个应用程序占用连续空间；为使地址转换不影响指令的进行速度，这种方式需要一个重定位寄存器的支持。

### 1.2 逻辑地址空间与物理地址空间

编译后，每个目标模块都从 0 号单元开始编址，这称为该目标模块的相对地址（或逻辑地址）。当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从 0 号单元开始编址的逻辑地址空间。用户程序和程序员只需知道逻辑地址，而内存管理的具体机制则是完全透明的，它们只有系统编程人员才会涉及。不同进程可以有相同的逻辑地址，因为这些相同的逻辑地址可以映射到主存的不同位置。

物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据，最后都要通过物理地址从主存中存取。当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址。这个过程称为地址地址重定位。

### 1.3 内存保护

内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。内存保护可采取两种方法。

1. 在 CPU 中设置一对上、下限寄存器，存分用户作业在主存中的下限和上限地址，每当 CPU 要访问一个地址时，分别和两个寄存器的值相比，判断有无越界。

2. 采用重定位寄存器（或基址寄存器）和界地址寄存器（又称限长寄存器）来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址的最大值。每个逻辑地址值必须小于界地址寄存器；内存管理机构动态地将逻辑地址与界地址寄存器进行比较，若未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。

   当 CPU 调度程序选择进程执行时,派遣程序会初始化重定位寄存器和界地址备存器。每个逻辑地址都需要与这两个寄存器进行核对，以保证操作系统和其他用户程序及数据不被该进程的运行影响。

   实现内存保护需要重定位寄存器和界地址寄存器，因此要注意两者的区别。重定位寄存器是用来 “加” 的，逻辑地址加上重定位寄存器中的值就能得到物理地址；界地址寄存器是用来 “比“ 的，通过比较界地址寄存器中的值与逻辑地址的值来判断是否越界。

## 2. 覆盖与交换

覆盖与交换技术是在多道程序环境下用来扩充内存的两种方法。

### 2.1 覆盖

早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但存储空间放不下用户进程的现象也经常发生，这一矛盾可以用覆盖技术来解决。

覆盖的基本思想如下：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可把用户空间分成一个固定区和若干覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。

覆盖技术的特点是，打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行，此外，内存中能够更新的地方只有覆盖区的段，不在覆盖区中的段会常驻内存。

### 2.2 交换

交换（对换）的基本思想是，把处于等待状态（或在 CPU 调度原则下被剩夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又称换出；把准备好竞争 CPU 运行的程序从辅存移到内存，这一过程又称接入。第 2 章介绍的中级调度采用的就是交换技术。

例如，有一个 CPU 采用时间片轮转调度算法的多道程序环境。时间片到，内存管理器将刚执行过的进程换出，将另一进程换入刚刚释放的内存空间。同时，CPU 调度器可以将时间片分配给其他已在内存中的进程。每个进程用完时间片都与另一进程交换。在理想情况下，内存管理器的交换过程速度足够快，总有进程在内存中可以执行。

有关交换，需要注意以下几个问题：

- 交换需要备份存储，通常是快速磁盘。它必须足够大，并提供对这些内存映像的直接访问。
- 为了有效使用 CPU，需要使每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比。
- 若换出进程，则必须确保该进程完全处于空闲状态。
- 交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用起来可能很快。
- 交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。
- 普通的交换使用不多，但交换策略的某些变体在许多系统中仍发挥作用。

交换技术主要在不同进程（或作业）之间进行，而覆盖则用于同一个程序或进程中。由于覆盖技术要求给出程序段之间的覆盖结构，使得其对用户和程序员不透明，所以对于主存无法存放用户程序的矛盾，现代操作系统是通过虚拟内存技术来解决的，覆盖技术则己成为历史；而交换技术在现代操作系统中仍具有较强的生命力。

## 3. 连续分配管理方式

为了能够将用户程序装入内存，必须为它分配一定大小的内存空间。连续分配方式是最早出现的一种存储器分配方式（任何一种新事物的发展，都是由直接转化到抽象的，如果不理解新事物的发展历程，很难接受其抽象形式）。顾名思义，给一个用户分配一个连续的内存空间，代码或数据的逻辑地址相邻，体现在内存空间分配时物理地址的相邻。

### 3.1 单一连续分配

内存在此方式下分为系统区和用户区，系统区仅供操作系统使用，通常在低地址部分；用户区是为用户提供的、除系统区之外的内存空间。这种方式无须进行内存保护。因为内存中永远只有一道程序，因此肯定不会因为访问越界而干扰其他程序。

这种方式的优点是简单、无外部碎片，可以采用覆盖技术，不需要额外的技术支持。缺点是只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低。

- 环境：单道程序环境
- 一个用户独占机器，内存被分为系统区和用户区，用户区仅装有一道用户程序，这样也就不需要包含机构了，大不了重启电脑。

### 3.2 固定分区分配

- 环境：多道程序环境

- 整个用户空间划分为若干个固定大小的区域，每个分区只能装入一道作业，这是最早也是最简单的一种可运行多道程序的分区式存储管理方式

- 若有空闲分区，从后备作业队列中选择一个适当大小的作业，装入该分区。

- 划分分区的方法有两种

  分区大小相同：缺点是缺乏灵活性，程序太大装不进去，程序太小浪费内存，这样在内部就存在空间浪费，这种现象称为内部碎片。尽管如此，还是有些场合需要处理多个相同程序的时候，这种方法还是很实用简单的。

  分区大小不等：增加存储器分配灵活性。分配之前需要对常在该系统运行的作业大小进行调查统计，然后再适当分配。

- 内存分配方式

  为了便于内存分配，通常将分区按其大小进行排队，并建立一张分区使用表如下

  | 分区号 | 大小（KB） | 起址（K） | 状态   |
  | ------ | ---------- | --------- | ------ |
  | 1      | 12         | 20        | 已分配 |
  | 2      | 32         | 32        | 已分配 |
  | 3      | 64         | 64        | 未分配 |
  | 4      | 128        | 128       | 已分配 |


固定分区是可用于多道程序涉及的最简单的存储分配，无外部碎片，但不能实现多进程共享一个主存区，所以存储空间利用率低。固定分区分配很少用于现在通用的操作系统中，但在某些用于控制多个相同对象的控制系统中仍发挥一定的作用。

### 3.3 动态分区分配

动态分区分配又称可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先划分内存，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此，系统中分区的大小和数目是可变的（P153）。

动态分区在开始分配时是很好的，但之后会导致内存中出现许多小的内存块。随着时间的推移，内存中会产生越来越多的碎片，内存的利用率随之下降。这些小的内存块称为外部碎片，指在所有分区外的存储空间会变成越来越多的碎片，这与固定分区中的内部碎片正好相对。克服外部碎片可以通过紧凑（Compaction）技术来解决，即操作系统不时地对进程进行移动和整理，但这需要动态重定位寄存器的支持，且相对费时。紧湊的过程实际上类似于  Windows 系统中的磁盘整理程序，只不过后者是对外存空间的紧凑。

在进程装入或换入主存时，若内存中有多个足够大的空闲块，则操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略。考虑以下几种算法:

1. 首次适应（First Fit）算法。空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足要求的第一个空闲分区。
2. 最佳适应（Best Fit）算法。空闲分区按容量递增的方式形成分区链，找到第一个能满足要求的空闲分区。
3. 最坏适应（Best Fit）算法。又称最大适应（Largest Fit）算法，空闲分区以容量递减的次序链接。找到第一个能满足要求的空闲分区，即挑选出最大的分区。
4. 邻近适应（Next Fit）算法。又称循环首次适应算法，由首次适应算法演变而成。不同之处是，分配内存时从上次查找结束的位置开始继续查找。

在这几种方法中，首次适应算法不仅是最简单的，而且通常也是最好和最快的。在 UNIX 系统的最初版本中，就是使用首次适应算法为进程分配内存空间的，它使用数组的数据结构（而非链表）来实现。不过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此增加了查找的开销。

邻近适应算法试图解决这个问题。但实际上，它常常导致在内存的末尾分配空间（因为在一遍扫描中，内存前面部分使用后再释放时，不会参与分配）分裂成小碎片。它通常比首次适应算法的结果要差。

最佳适应算法虽然称为 “最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存块，会产生最多的外部碎片。

最坏适应算法与最佳适应算法相反，它选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的连续内存划分开，会很快导致没有可用的大内存块，因此性能也非常差。

Knuth 和 Shore 分别就前三种方法对内存空间的利用情况做了模拟实验，结果表明：首次适应算法可能比最佳适应法效果好，而它们两者一定比最大适应法效果好。另外要注意，在算法实现时，分配操作中最佳适应法和最大适应法需要对可用块进行排序或遍历查找，而首次适应法和邻近适应法只需要简单査找；在回收操作中，当回收的块与原来的空闲块相邻时（有三种相邻的情况，比较复杂），需要将这些块合并。在算法实现时，使用数组或链表进行管理。除了内存的利用率，这里的算法开销也是操作系统设计需要考虑的一个因素。

三种内存分区管理方法有一个共同特点，即用户进程（或作业）在主存中都是连续存放的。

## 4. 非连续分配管理方式

非连续分配允许一个程序分散地装入不相邻的内存分区。在连续分配管理方式中，我们发现，即使内存有超过 1GB 的空闲空间，但若没有连续的1GB 空间，则需要 1GB 空间的作业仍然是无法运行的；但若采用非连续分配管理方式，则作业所要求的 1GB 内存空间可以分散地分配在内存的各个区域，当然，这也需要额外的空间去存储它们（分散区域）的索引，使得非连续分配方式的存储密度低于连续存储方式。

非连续分配管理方式根据分区的大小是否固定，分为分页存储管理方式和分段存储管理方式。

在分页存储管理方式中，又根据运行作业时是否把作业的所有页面都装入内存才能运行，分为基本分页存储管理方式和请求分页存储管理方式。下面介绍基本分页存储管理方式。

### 4.1 基本分页存储管理方式

固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低。我们希望内存的使用能尽量避免碎片的产生，这就引入了分页的思想：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。

分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。但它又有本质的不同点：块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但这种碎片相对于进程来说也是很小的，每个进程平均只产生半个块大小的内部碎片（也称页内碎片）。

1. 分页存储的几个基本概念

   1. 页面和页面大小。进程中的块称为页（Page）；内存中的块称为页框（Page Frame，或页帧）。外存也以同样的单位进行划分，直接称为块（Block）。进程在执行时需要申请主存空间，即要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。

      为方便地址转换，页面大小应是 2 的整数幂。同时页面大小应该适中，页面太小会使进程的页面数过多，这样页表就会过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换入/换出的效率；页面过大又会使页内碎片增多，降低内存的利用率。所以页面的大小应该适中，要在空间效率和时间效率之间权衡。

   2. 地址结构。分页存储管理的逻辑结构如下

      ```markdown
      31 ...  12 |  11 ... 0
         页号 P     页内偏移量 W
      ```

      地址结构包含两部分：前一部分为页号 P，后一部分为页内偏移量 W。地址长度为 32 位，其中 0~11 位为页内地址，即每页大小为 4KB；12~31 位为页号，地址空间最多允许 2²⁰ 页。

      注意，地址结构决定了虚拟内存的寻址空间有多大。在实际问题中，页号、页内偏移、逻辑地址大多都是由十进制给出的。题目用二进制地址的形式给出时，读者要会转换。

   3. 页表。为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表,它记录页面在内存中对应的物理块号，页表一般存放在内存中。

      页表是由页表项组成的，初学者容易混淆页表项与地址结构，页表项与地址都由两部分构成，而且第一部分都是页号，但页表项的第二部分是物理内存中的块号，而地址的第二部分是页内偏移；页表项的第二部分与地址的第二部分共同组成物理地址。

      在配置页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作用是实现从页号到物理块号的地址映射（P156）。

2. 基本地址变换机构

   地址变换机构的任务是将逻辑地址转换为内存中的物理地址，地址变换是借助于页表实现的（P156）。

   在系统中通常设置一个页表寄存器（PTR），存放页表在内存的始址 F 和页表长度 M。进程未执行时，页表的始址和长度存放在进程控制块中，当进程执行时，才将页表始址和长度存入页表寄存器。设页面大小为 L，逻辑地址 A 到物理地址 E 的变換过程如下（逻地地址、页号、每页的长度都是十进制数）：

   1. 计算页号 P（P=A/L）和页内偏移量 W（W=A%L）。
   2. 比较页号 P 和页表长度 M，若 P≥M，则产生越界中断，否则继续执行。
   3. 页表中页号 P 对应的页表项地址 = 页表始址 F + 页号 P × 页表项长度，取出该页表项内容 b，即为物理块号。要注意区分页表长度和页表项长度。页表长度的值是指一共有多少页，页表项长度是指页地址占多大的存储空间。
   4. 计算 E=b×L+W，用得到的物理地址 E 去访问内存。

   以上整个地址变换过程均是由硬件自动完成的。例如，若页面大小 L 为 1KB，页号 2 对应的物理块为 b=8，计算逻辑地址 A=2500 的物理过程如下：P=2500/1K=2，W=2500%1K=452，查找得到页号 2 对应的物理块的块号为 8，E=8×1024+452=8644。

   要再次提醒读者的是，题目中条件用十进制数给出和用二进制数给出的处理过程会稍有不同。同时读者会发现，页式管理只需给出一个整数就能确定对应的物理地址，因为页面大小 L 是固定的。因此，页式管理中地址空间是一维的。

   页表项的大小不是随意规定的，而是有所约束的。如何确定页表项的大小?

   页表项的作用是找到该页在内存中的位置。以 32 位逻辑地址空间、字节编址单位、一页 4KB 为例，地址空间内一共有 2³²B/4KB=1M 页，因此需要 log₂1M = 20位 才能保证表示范围能容纳所有页面，又因为以字节作为编址单位，即页表项的大小 ≥ 20/8 上取整 = 3B。所以在这个条件下，为了保证页表项能够指向所有页面，页表项的大小应该大于 3B，当然，也可选择更大的页表项让个页面能够正好容下整数个页表项，进而方便存储（如取成 4B，一页正好可以装下 1K 个页表项)，或增加一些其他信息。

   下面讨论分页管理方式存在的两个主要问题：

   1. 每次访存操作都需要进行逻辑地址到物理地址的转换，地址转换过程必须足够快，否则访存遠度会低
   2. 每个进程引入页表，用于存储映射机制，页表不能太大，否则内存利用率会降低。

3. 具有快表的地址变换结构

   由上面介绍的地址变换过程可知，若页表全部放在内存中，则存取一个数据或一条指令至少要访问两次内存：第一次是访问页表，确定所存取的数据或指令的物理地址；第二次是根据该地址存取数据或指令。显然，这种方法比通常执行指令的速度慢了一半。

   为此，在地址变换机构中增设一个具有并行査找能力的高速缓冲存储器 ~ 快表，又称相联存储器（TLB），用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，主存中的页表常称为慢表（P157）。

   在具有快表的分页机制中，地址的变换过程如下：

   1. CPU 给出逻辑地址后，由硬件进行地址转换，将页号送入高速缓存寄存器，并将此页号与快表中的所有页号进行比较。
   2. 若找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框号，与页内偏移量拼接形成物理地址。这样，存取数据仅一次访存便可实现。
   3. 若未找到，则需要访问主存中的页表，在读出页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表己满，则必须按照一定的算法对旧的页表项进行替换。

   注意：有些处理机设计为快表和慢表同时查找，若在快表中查找成功则终止慢表的查找。

   一般快表的命中率可达 90% 以上，这样分页带来的速度损失就可降低至 10% 以下。快表的有效性基于著名的局部性原理，后面的虚拟内存中将会具体讨论它。

4. 两级页表

   由于引入了分页管理，进程在执行时不需要将所有页调入内存页框，而只需将保存有映射关系的页表调入内存。但是，我们仍然需要考虑页表的大小。以 32 位逻辑地址空间、页面大小 4KB 页表项大小 4B 为例，若要实现进程对全部逻地址空间的映射，则每个进程需要 2²⁰ 即约 100万 个页表项。也就是说，每个进程仅页表这一项就需要 4MB 主存空间，这显然是不切实际的，即使不考虑对全部逻地址空间进行映射的情况，一个逻辑地址空间稍大的进程，其页表大小也可能是过大的。以一个 40MB 的进程为例，页表项 40KB（40MB/4KBx4B)，若将所有页表项内容保存在内存中，则需要 10 个内存页框来保存整个页表。整个进程大小约为 1 万个页面，而实际执行时只需要几十个页面进入内存页框就可运行，但若要求 10 个页面大小的页表必须全部进入内存，则相对实际执行时的几十个进程页面的大小来说，肯定降低了内存利用率；从另一方面来说，这10页的页表项也并不需要同时保存在内存中，因为在大多数情况下，映射所需要的页表项都在页表的同一个页面中。

   为了压缩页表，我们进一步延伸页表映射的思想，就可得到二级分页，即使用层次结构的页表：将页表的10页空间也进行地址映射，建立上一级页表，用于存储页表的映射关系。这里对页表的 10 个页面进行映射只需要 10 个页表项，所以上一级页表只需要 1 页就已足够（可以存储 2¹⁰=1024 个页表项)。在进程执行时，只需要将这一页的上一级页表调入内存即可，进程的页表和进程本身的页面可在后面的执行中再调入内存。根据上面提到的条件（32 位逻辑地址空间、页面大小 4KB、页表项大小 4B，以字节为编址单位），我们来构造一个适合的页表结构。页面大小为 4KB，页内偏移地址为 log₂4K=12 位，页号部分为 20 位，若不采用分级页表，则光页表就要占用 2²⁰×4B/4KB=1024 页，这大大超过了许多进程自身需要的页面，对于内存来说是非常浪费
   资源的，而且査询页表工作也会变得十分不便，试想若把这些项表放在连的空间内，查询对应页的物理页号时可以通过 页表首项地址+页号x4B 的形式得到，而这种方法查询起来虽然相对方使，但连续的 1024 页对于内存的要求实在太高，并且上面也说到了其中大多数页而都是不会用到的，所以这种方法并不具有可行性。若不把这些页表放在连续的空间里,则需要一张索引表来告诉我们第几张项表该上哪里去找，这能解决页表的查询问题，且不用把所有的页表都调入内存，只在需要它时才调入（下节介绍的虚拟存储器思想），因此能解决占用内存空间过大的问题。读者也许发现这个方案就和当初引进页表机制的方式一模一样，实际上就是构造一个页表的页表，也就是二级页表。为查询方使，顶级页表最多只能有 1 个页面（一定要记住这个规定），因此顶
   级项表总共可以容纳 4KB/4B=1K 个页表项，它占用的地址位数为 log₂1K=10 位，而之前已经计算出页内偏移地址占用了 12 位，因此一个 32 位的地址空间就剩下了 10 位，正好使得二级项表的大小在一页之内，这样就得到了逻地址空间的格式，如下

   ```c
   一级页号(10位)  + 二级页号(10位) + 页内偏移(12位)
   ```

   二级页表实际上是在原有页表结构上再加上一层页表（P159）。

   建立多级页表的目的在于建立索引，以便不用浪费主存空间去存储无用的页表项，也不用盲目地顺序式查找页表项。

### 4.2 基本分段存储管理方式

分页管理方式是从计算机的角度考虑设计的，目的是提高内存的利用率，提升计算机的性能；分页通过硬件机制实现，对用户完全透明。分段管理方式的提出则考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长及动态链接等方面的需要。

1. 分段。段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为 5 段，每段从 0 开始编址，并分配一段连续的地址空间（段内要求连续，段间不要求连续，段长不固定，因此整个作业的地址空间是二维的），其逻辑地址由段号 S 与段内偏移量 W 两部分组成。段号为 16 位，段内偏移量为 16 位，因此一个作业最多有 2¹⁶=65536 段，最大段长为 64KB。

   在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显式提供，在高级程序设计语言中，这个工作由编译程序完成。

2. 段表。每个进程都有一张逻辑空间与内存空间映射的段表，其中每个段表对应进程的一段，段表项记录该段在内存中的始址和长度。段表的内容如下

   ```c
   段号  +  段长  +  本段在主存的始址
   ```

   配置段表后，执行中的进程可通过查找段表，找到每段所对应的内存区。可见，段表用于实现从逻辑段到物理内存的映射（P160）。

3. 地址变换机构。为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表始址 F 和段表长度 M。从逻辑地址 A 到物理地址 E 之间的地址变换过程如下

   1. 从逻辑地址 A 中取出前几位为段号 S，后几位为段内偏移量 F，注意在段式存储管理的题目中，逻辑地址一般以二进制数给出，而在页式存储管理中，逻辑地址一般以十进制数给出,读者要具体问题具体分析。
   2. 比较段号 S 和段表长度 M，若 S≥M，则产生越界中断，否则继续执行。
   3. 段表中段号 S 对应的段表项地址 = 段表始址 F + 段号 S x 段表项长度，取出该段表项的前几位得到段长  C。若 段内偏移量≥C，则产生越界中断，否则继续执行。从这句话我们可以看出，段表项实际上只有两部分，前几位是段长，后几位是始址。
   4. 取出段表项中该段的始址 b，计算 E=b+W，用得到的物理地址 E 去访问内存。

4. 段的共享与保护。在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的。当一个作业正从共享段中读取数据时，必须防止另个作业修改此共享段中的数据。不能修改的代码称为纯代码或可重入代码(它不属于临界资源)，这样的代码和不能修改的数据可以共享，而可修改的代码和数据不能共享。

   与分页管理类似，分段管理的保护方法主要有两种：一种是存取控制保护，另一种是地址越界保护。地址越界保护将段表寄存器中的段表长度与逻辑地址中的段号比较，若段号大于段表长度，则产生越界中断；再将段表项中的段长和逻辑地址中的段内位移进行比较，若段内位移大于段长，也会产生越界中断。分页管理中的地址越界保护只需要判断页号是否越界，页内偏移是不可能越界的。

   与页式管理不同，段式管理不能通过给出一个整数便确定对应的物理地址，因为每段的长度是不固定的，无法通过整数除法得出段号，无法通过求余得出段内偏移，所以段号和段内偏移一定要显式给出（段号，段内偏移），因此分段管理的地址空间是二维的。

### 4.3 段页式管理方式

页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。将这两种存储管理方法结合起来，便形成了段页式存储管理方式。

在段页式系统中，作业的地址空间首先被分成若干逻辑段，每段都有自己的段号，然后将每段分成若干大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干和页面大小相同的存储块，对内存的分配以存储块为单位（P161）。

在段页式系统中，作业的逻辑地址分为三部分：段号、页号和页内偏移量，如下：

```c
段号 S + 页号 P + 页内偏移量 W
```

为了实现地址变换，系统为毎个进程建立一张段表，每个分段有一张页表。段表表项中至少包括段号、页表长度和页表始址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存器，指出作业的段表始址和段表长度（段表寄存器和页表寄存器的作用都有两个，一是在段表或页表中寻址，二是判断是否越界）。

注意：在一个进程中，段表只有一个，而页表可能有多个。

在进行地址变换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最后形成物理地址。进行一次访问实际需要三次访问主存（P162），这里同样可以使用快表来加快查找速度，其关键字由段号、页号组成，值是对应的页帧号和保护码。

结合上面对段式管理和页式管理的地址空间的分析，可以得到结论：段页式管理的地址空间是二维的。

## 5. 小结

本节开头提出的问题的参考答案如下。

1. 为什么要进行内存管理？

   在单道批处理系统阶段，一个系统在一个时间段内只执行一个程序，内存的分配极其简单，即仅分配给当前运行的进程。引入多道程序的并发执行后，进程之间共享的不仅仅是处理机，还有主存储器。然而，共享主存会形成一些特殊的挑战。若不对内存进行管理，则容易导致内存数据的混乱，以至于限制进程的并发执行。因此，为了更好地支持多道程序并发执行，必须进行内存管理。

2. 页式管理中每个页表项大小的下限如何决定？

   页表项的作用是找到该页在内存中的位置。以 32 位逻辑地址空间、字节编址单位、一页 4KB 为例，地址空间内共含有 2³²B/4KB=1M 页，需要 log₂1M=20 位 才能保证表示范围能容纳所有页面，又因为以字节作为编址单位，即页表项的大小 ≥20/8上取整=3B。所以在这个条件下，为了保证页表项能够指向所有页面，页表项的大小应该大于 3B；当然，也可选择更大的页表项大小，让一个页面能够正好容下整数个页表项，以方便存储（例如取成 4B，一页正好可以装下 1K 个页表项），或增加一些其他信息。

3. 多级页表解决了什么问题？又会带来什么问题？

   多级页表解决了当逻辑地址空间过大时，页表的长度会大大增加的问题。而采用多级页表时，一次访盘需要多次访问内存甚至磁盘，会大大增加一次访存的时间。

   不少读者表示本节的内容难以掌握，实际上本节的内容并不难，只要抓住下列几个关键的线索，本节的所有知识点就能了然于胸。

   无论是段式管理、页式管理还是段页式管理，读者都只需要关注三个问题

   1. 逻辑地址结构。
   2. 表项结构。
   3. 寻址过程。

   搞清楚这三个问题，就相当于搞清楚了上面几种存储管理方式。再次提醒读者区分逻辑地址结构和表项结构。